# 第二屆《機器學習百日馬拉松》
### 資料清理數據前處理
*  DAY1: 資料分析與評估
*  DAY2: EDA-1/讀取資料EDA: Data summary
*  DAY3: 3-1如何新建一個 dataframe? 3-2 如何讀取其他資料? (非 csv 的資料)
*  DAY4: EDA: 欄位的資料類型介紹及處理
*  DAY5: EDA資料分佈
*  DAY6: EDA: Outlier 及處理
*  DAY7: 常用的數值取代：中位數與分位數連續數值標準化
*  DAY8: DataFrame operationData frame merge/常用的 DataFrame 操作
*  DAY9: EDA: correlation/相關係數簡介
* DAY10: EDA from Correlation 
* DAY11: EDA: 不同數值範圍間的特徵如何檢視/繪圖與樣式Kernel Density Estimation (KDE)
* DAY12: EDA: 把連續型變數離散化
* DAY13: 程式實作 把連續型變數離散化
* DAY14: Subplots
* DAY15: Heatmap & Grid-plot
* DAY16: 模型初體驗 Logistic Regression
### 資料科學特徵工程技術
* DAY17: 特徵工程簡介
* DAY18: 特徵類型
* DAY19: 數值型特徵-補缺失值與標準化
* DAY20: 數值型特徵-去除離群值
* DAY21: 數值型特徵-去除偏態
* DAY22: 類別型特徵-基礎處理
* DAY23: 類別型特徵-均值編碼
* DAY24: 類別型特徵-其他進階處理
* DAY25: 時間型特徵
* DAY26: 特徵組合-數值與數值組合
* DAY27: 特徵組合-類別與數值組合
* DAY28: 特徵選擇
* DAY29: 特徵評估
* DAY30: 分類型特徵優化-葉編碼
### 機器學習基礎模型建立
* DAY31: 機器學習概論
* DAY32: 機器學習-流程與步驟
* DAY33: 機器如何學習
* DAY34: 訓練/測試集切分的概念
* DAY35: Regression v.s Classification
* DAY36: 評估指標選定/Evaluation metrics
* DAY37: Regression model介紹-線性回歸/羅吉斯回歸
* DAY38: Regression model-線性/羅吉斯回歸模型程式碼撰寫
* DAY39: Regression model介紹-LASSO回歸/Ridge回歸
* DAY40: Regression model-LASSO/Ridge回歸程式碼撰寫
* DAY41: Tree based model-決策樹(Desion Tree)模型介紹
* DAY42: Tree based model-決策樹程式碼撰寫
* DAY43: Tree based model-隨機森林(Random Forest)介紹
* DAY44: Tree based model-隨機森林程式碼撰寫
* DAY45: Tree based model-梯度提升機(Gradient Boosting Machine)介紹
* DAY46: Tree based model-梯度提升機程式碼撰寫
### 機器學習調整參數
* DAY47: 超參數調整與優化
* DAY48: Kaggle競賽平台介紹
* DAY49: 集成方法:混合泛化(Blending)
* DAY50: 集成方法:堆疊泛化(Stacking)
### 非監督式機器學習
* DAY54: Clustering1 - 非監督式機器學習簡介
* DAY55: Clustering2 - 聚類算法
* DAY56: K-mean觀察:使用輪廓分析
* DAY57: Clustering3 - 階層分群算法
* DAY58: 階層分群法觀察:使用2D樣板資料集
* DAY59: Dimension Reduction1 - 降維方法-主成份分析
* DAY60: PCA觀察:使用手寫辨識資料集
* DAY61: Dimension Reduction2 - 降維方法-T-SNE
* DAY62: T-SNE觀察:分群與流形還原
### 深度學習理論與實作
* DAY63: 神經網路介紹
* DAY64: 深度學習體驗:模型調整與學習曲線
* DAY65: 深度學習體驗:啟動函數與正規化

